# üìù Publications


## ü¶∏ Digital Human

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='../images/geneface++.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Geneface++: Generalized and Stable Real-Time Audio-Driven 3D Talking Face Generation](https://arxiv.org/abs/2305.00787) \\
**Zhenhui Ye**, Jinzheng He, Ziyue Jiang, Rongjie Huang, Jiangwei Huang, Jinglin Liu, Yi Ren, Xiang Yin, Zejun Ma, Zhou Zhao

[**Project**](https://github.com/yerfor/GeneFace) [![img](https://img.shields.io/github/stars/yerfor/GeneFace?style=social)](https://github.com/yerfor/GeneFace)

- GeneFace++ is a modern talking face system that aims to achieve the goal of generalized lip synchronization, good video quality, and high system efficiency.
- It greatly improves the stability and efficiency of NeRF-based methods.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2023</div><img src='../images/geneface.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Geneface: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://arxiv.org/abs/2301.13430) \\
**Zhenhui Ye**, Ziyue Jiang, Yi Ren, Jinglin Liu, Jinzheng He, Zhou Zhao

[**Project**](https://github.com/yerfor/GeneFace) [![img](https://img.shields.io/github/stars/yerfor/GeneFace?style=social)](https://github.com/yerfor/GeneFace)

- GeneFace is a NeRF-based talking face system that generalizes well to various OOD audios.
- It first utilizes a generative model to model the audio-to-motion mapping.

</div>
</div>


## üéô Speech Synthesis


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2023</div><img src='../images/clapspeech.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-Training](https://arxiv.org/abs/2204.11792) \\
**Zhenhui Ye**, Rongjie Huang, Yi Ren, Ziyue Jiang, Jinglin Liu, Jinzheng He, Zhou Zhao

[**Project**](https://github.com/yerfor/CLAPSpeech) [![img](https://img.shields.io/github/stars/yerfor/CLAPSpeech?style=social)](https://github.com/yerfor/CLAPSpeech)

- CLAPSpeech is the first cross-modal contrastive learning method that focus on extracting prosody-related text representation for text-to-speech (TTS).
- It provides a convenient plug-in text encoder applicable for all TTS models to improve prosody.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2022</div><img src='../images/synta.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SyntaSpeech: Syntax-Aware Generative Adversarial Text-to-Speech](https://arxiv.org/abs/2204.11792) \\
**Zhenhui Ye**, Zhou Zhao, Yi Ren, Fei Wu

[**Project**](https://github.com/yerfor/SyntaSpeech) [![img](https://img.shields.io/github/stars/yerfor/SyntaSpeech?style=social)](https://github.com/yerfor/SyntaSpeech)

- SyntaSpeech is the first syntax-aware non-autoregressive TTS acoustic model.
- We design a syntatic graph encoder to extract syntax-related prosody from text.

</div>
</div>

- [Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech](https://arxiv.org/abs/2206.02147), Ziyue Jiang, Zhe Su, Zhou Zhao, Qian Yang, Yi Ren, Jinglin Liu, **Zhenhui Ye**, **NeurIPS 2022**, [![](https://img.shields.io/github/stars/Zain-Jiang/Dict-TTS?style=social&label=Code+Stars)](https://github.com/Zain-Jiang/Dict-TTS)


## üìö Deep Reinforcement Learning

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TMC 2022</div><img src='../images/drgn.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Soft-DRGN: Multi-UAV Navigation for Partially Observable Communication Coverage by Graph Reinforcement Learning](https://ieeexplore.ieee.org/document/9697395) \\
**Zhenhui Ye**, Ke Wang, Yining Chen, Xiaohong Jiang, Guanghua Song. 

**IEEE transactions on Mobile Computing 2022** 

[**Project**](https://github.com/yerfor/Soft-DRGN) [![img](https://img.shields.io/github/stars/yerfor/Soft-DRGN?style=social)](https://github.com/yerfor/Soft-DRGN)
 
- We propose Soft-DRGN to learn robust stochastic policies for large-scale multi-agent cooperation.
- We propose to utilize graph attention network to learn the inter-agent communication.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Applied Intelligence 2022</div><img src='../images/experience_augmentation.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [Improving Sample Efficiency in Multi-Agent Actor-Critic Methods](https://link.springer.com/article/10.1007/s10489-021-02554-5)\\
**Zhenhui Ye**, Yining Chen, Xiaohong Jiang, Guanghua Song, **Applied Intelligence 2022**

- We propose Experience Augmentation (EA) to improve the sample efficiency for homogeneous MARL tasks.
- We propose a sample-efficient training pipeline called PEDMA.

</div>
</div>

- [Multi-agent Deep Reinforcement Learning for Voltage Control with Coordinated Active and Reactive Power Optimization](https://ieeexplore.ieee.org/document/9805763), Daner Hu, **Zhenhui Ye**, Yuanqi Gao, Zuzhao Ye, Yonggang Peng, Napeng Yu, **IEEE transactions on Smart Grid 2022**
