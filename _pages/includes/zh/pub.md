# ğŸ“ å­¦æœ¯è®ºæ–‡


## ğŸ¦¸ è¯´è¯äººè§†é¢‘åˆæˆï¼ˆè™šæ‹Ÿäººï¼‰

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv</div><img src='../images/geneface++.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Geneface++: Generalized and Stable Real-Time Audio-Driven 3D Talking Face Generation](https://arxiv.org/abs/2305.00787) \\
**Zhenhui Ye**, Jinzheng He, Ziyue Jiang, Rongjie Huang, Jiangwei Huang, Jinglin Liu, Yi Ren, Xiang Yin, Zejun Ma, Zhou Zhao

[**Project**](https://github.com/yerfor/GeneFace) [![img](https://img.shields.io/github/stars/yerfor/GeneFace?style=social)](https://github.com/yerfor/GeneFace)

- GeneFace++ æ˜¯ä¸€ä¸ªå…ˆè¿›çš„è™šæ‹Ÿäººåˆæˆç³»ç»Ÿï¼Œå®ƒè‡´åŠ›äºå®ç°é«˜æ³›åŒ–çš„è¯­éŸ³-å˜´å½¢å¯¹é½ã€ä¼˜ç§€çš„è§†é¢‘è´¨é‡å’Œé«˜ç³»ç»Ÿæ•ˆç‡ã€‚
- å®ƒå¤§å¤§æå‡äº†ç°æœ‰åŸºäºNeRFçš„è™šæ‹Ÿäººç®—æ³•çš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2023</div><img src='../images/geneface.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Geneface: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://arxiv.org/abs/2301.13430) \\
**Zhenhui Ye**, Ziyue Jiang, Yi Ren, Jinglin Liu, Jinzheng He, Zhou Zhao, **ICLR 2023**

[**Project**](https://github.com/yerfor/GeneFace) [![img](https://img.shields.io/github/stars/yerfor/GeneFace?style=social)](https://github.com/yerfor/GeneFace)

- GeneFaceæ˜¯ä¸€ä¸ªåŸºäºNeRFçš„è™šæ‹Ÿäººåˆæˆç®—æ³•ï¼Œå®ƒå¯¹åŸŸå¤–è¯­éŸ³ï¼ˆå¦‚æ­Œå£°ã€è·¨æ€§åˆ«éŸ³é¢‘ï¼‰å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ã€‚
- å®ƒé¦–æ¬¡æå‡ºç”¨ç”Ÿæˆæ€§æ¨¡å‹å»ºæ¨¡è¯­éŸ³åˆ°é¢éƒ¨åŠ¨ä½œçš„æ˜ å°„ã€‚

</div>
</div>


## ğŸ™ è¯­éŸ³åˆæˆ

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2023</div><img src='../images/clapspeech.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-Training](https://arxiv.org/abs/2204.11792) \\
**Zhenhui Ye**, Rongjie Huang, Yi Ren, Ziyue Jiang, Jinglin Liu, Jinzheng He, Yin Xiang, Zhou Zhao, **ACL 2023**

[**Project**](https://github.com/yerfor/CLAPSpeech) [![img](https://img.shields.io/github/stars/yerfor/CLAPSpeech?style=social)](https://github.com/yerfor/CLAPSpeech)

- CLAPSpeechæ˜¯é¦–ä¸ªèšç„¦äºæå–éŸµå¾‹ç›¸å…³çš„æ–‡æœ¬è¡¨å¾å­¦ä¹ å·¥ä½œã€‚ä¹Ÿæ˜¯é¦–ä¸ªå°†æ–‡æœ¬-è¯­éŸ³è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ç”¨äºè¯­éŸ³åˆæˆé¢†åŸŸçš„å·¥ä½œã€‚
- å®ƒä¸ºç°æœ‰çš„è¯­éŸ³åˆæˆç³»ç»Ÿæä¾›äº†ä¸€ä¸ªæ–¹ä¾¿å¯æ’æ‹”çš„æ–‡æœ¬ç¼–ç å™¨ï¼Œå¯ä»¥æ˜æ˜¾æå‡ç°æœ‰è¯­éŸ³åˆæˆæ¨¡å‹çš„éŸµå¾‹æ€§èƒ½ã€‚

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2022</div><img src='../images/synta.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SyntaSpeech: Syntax-Aware Generative Adversarial Text-to-Speech](https://arxiv.org/abs/2204.11792) \\
**Zhenhui Ye**, Zhou Zhao, Yi Ren, Fei Wu, **IJCAI 2022**

[**Project**](https://github.com/yerfor/SyntaSpeech) [![img](https://img.shields.io/github/stars/yerfor/SyntaSpeech?style=social)](https://github.com/yerfor/SyntaSpeech)

- SyntaSpeechæ˜¯é¦–ä¸ªå¥æ³•æ„ŸçŸ¥çš„éè‡ªå›å½’è¯­éŸ³åˆæˆæ¨¡å‹ã€‚ 
- æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä»çº¯æ–‡æœ¬æ„å»ºå¥æ³•å›¾çš„æ–¹æ³•å’Œä¸€ä¸ªå¯¹åº”çš„å›¾ç¼–ç å™¨ï¼Œå®ƒå¯ä»¥ä»è¾“å…¥çš„æ–‡æœ¬ä¸­æå–æœ‰ç”¨çš„å¥æ³•ä¿¡æ¯ï¼Œä»¥æå‡éŸµå¾‹å»ºæ¨¡ã€‚

</div>
</div>

- [Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech](), Ziyue Jiang, Zhe Su, Zhou Zhao, Qian Yang, Yi Ren, Jinglin Liu, **Zhenhui Ye**, **NeurIPS 2022**, [![](https://img.shields.io/github/stars/Zain-Jiang/Dict-TTS?style=social&label=Code+Stars)](https://github.com/Zain-Jiang/Dict-TTS)


## ğŸ“š æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IEEE TMC 2022</div><img src='../images/drgn.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multi-UAV Navigation for Partially Observable Communication Coverage by Graph Reinforcement Learning](https://ieeexplore.ieee.org/document/9697395) \\
**Zhenhui Ye**, Ke Wang, Yining Chen, Xiaohong Jiang, Guanghua Song. 

**IEEE transactions on Mobile Computing 2022** 

[**Project**](https://github.com/yerfor/Soft-DRGN) [![img](https://img.shields.io/github/stars/yerfor/Soft-DRGN?style=social)](https://github.com/yerfor/Soft-DRGN)

- æˆ‘ä»¬æå‡ºSoft-DRGNç®—æ³•ï¼Œä»¥åœ¨å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“å†™ä½œä»»åŠ¡ä¸­è®­ç»ƒé²æ£’é«˜æ•ˆçš„éšæœºæ€§ç­–ç•¥ã€‚
- æˆ‘ä»¬æå‡ºåˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œå®ç°å¤šæ™ºèƒ½ä½“é—´å¯å­¦ä¹ çš„é€šè®¯åä½œã€‚

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Applied Intelligence 2022</div><img src='../images/experience_augmentation.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [Improving Sample Efficiency in Multi-Agent Actor-Critic Methods](https://link.springer.com/article/10.1007/s10489-021-02554-5) \\
**Zhenhui Ye**, Yining Chen, Xiaohong Jiang, Guanghua Song, **Applied Intelligence 2022**

- æˆ‘ä»¬æå‡ºç»éªŒå¢å¼ºï¼ˆExperience Augmentationï¼‰æœºåˆ¶ï¼Œä»¥æå‡åŒæ„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä»»åŠ¡çš„æ ·æœ¬æ•ˆç‡ã€‚
- æˆ‘ä»¬æå‡ºäº†PEDMAï¼Œä¸€ä¸ªé«˜æ ·æœ¬æ•ˆç‡çš„MARLè®­ç»ƒæ–¹æ¡ˆã€‚

</div>
</div>

- [Multi-agent Deep Reinforcement Learning for Voltage Control with Coordinated Active and Reactive Power Optimization](https://ieeexplore.ieee.org/document/9805763), Daner Hu, **Zhenhui Ye**, Yuanqi Gao, Zuzhao Ye, Yonggang Peng, Napeng Yu, **IEEE transactions on Smart Grid 2022**
